{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "TAVILY_API_KEY = os.getenv(\"TAVILY_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\n",
    "    \"C:/Users/waled/Desktop/chamwings/Policies.pdf\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "embedding_function = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "vector_store = Chroma(embedding_function=embedding_function,persist_directory=\"C:/Users/waled/Desktop/chamwings/EmployeeChatBot/policies\",  # Where to save data locally, remove if not neccesary\n",
    ")\n",
    "\n",
    "retriever = vector_store.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "from typing import List, Dict, Any\n",
    "from sqlalchemy import create_engine, text\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.runnables import ensure_config\n",
    "DATABASE_URL = os.getenv(\"DATABASE_URL\", \"mysql://root:@localhost/chamwings\")\n",
    "engine = create_engine(DATABASE_URL)\n",
    "@tool\n",
    "def fetch_user_flight_information() -> List[Dict[str, Any]]:\n",
    "    \"\"\"Fetch all reservations for the user along with corresponding flight information and seat assignments.\n",
    "\n",
    "    Returns:\n",
    "        A list of dictionaries where each dictionary contains the reservation details,\n",
    "        associated flight details, and the seat assignments for each reservation belonging to the user.\n",
    "    \"\"\"\n",
    "    config = ensure_config()  # Fetch from the context\n",
    "    configuration = config.get(\"configurable\", {})\n",
    "    passenger_id = configuration.get(\"passenger_id\", None)\n",
    "    if not passenger_id:\n",
    "        raise ValueError(\"No passenger ID configured.\")\n",
    "        \n",
    "    query = text(\"\"\"\n",
    "        SELECT \n",
    "            r.reservation_id AS ticket_no, \n",
    "            r.status AS booking_status,\n",
    "            f.flight_id, \n",
    "            f.flight_number, \n",
    "            dep_airport.airport_name AS departure_airport, \n",
    "            arr_airport.airport_name AS arrival_airport,\n",
    "            s.departure_date AS scheduled_departure, \n",
    "            s.arrival_date AS scheduled_arrival,\n",
    "            fs.seat_id AS seat_no, \n",
    "            fs.status AS seat_status\n",
    "        FROM \n",
    "            reservations r\n",
    "            JOIN flights f ON r.flight_id = f.flight_id\n",
    "            JOIN airports dep_airport ON f.departure_airport = dep_airport.airport_id\n",
    "            JOIN airports arr_airport ON f.arrival_airport = arr_airport.airport_id\n",
    "            JOIN schedule_days s ON f.flight_id = s.flight_id\n",
    "            LEFT JOIN flight_seats fs ON f.flight_id = fs.flight_id\n",
    "        WHERE \n",
    "            r.passenger_id = :passenger_id\n",
    "    \"\"\")\n",
    "\n",
    "    with engine.connect() as connection:\n",
    "        result = connection.execute(query, {\"passenger_id\": passenger_id})\n",
    "        return [dict(row._mapping) for row in result]  # Use row._mapping to access row as a dictionary\n",
    "@tool\n",
    "def search_flights(departure_airport: int, arrival_airport: int, departure_date: datetime.date) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Search for available flights based on departure and arrival airports and date.\n",
    "    \"\"\"\n",
    "    query = text(\"\"\"\n",
    "        SELECT f.flight_id, f.flight_number, f.departure_terminal, f.arrival_terminal, \n",
    "               f.price, (a.capacity - f.number_of_reserved_seats) as available_seats\n",
    "        FROM flights f\n",
    "        JOIN airplanes a ON f.airplane_id = a.airplane_id\n",
    "        WHERE f.departure_airport = :departure_airport\n",
    "        AND f.arrival_airport = :arrival_airport\n",
    "        AND DATE(f.departure_terminal) = :departure_date\n",
    "    \"\"\")\n",
    "    \n",
    "    with engine.connect() as connection:\n",
    "        result = connection.execute(query, {\n",
    "            \"departure_airport\": departure_airport,\n",
    "            \"arrival_airport\": arrival_airport,\n",
    "            \"departure_date\": departure_date\n",
    "        })\n",
    "        # return [dict(row) for row in result]\n",
    "        return [dict(row._mapping) for row in result]  # Use row._mapping to access row as a dictionary\n",
    "@tool\n",
    "def lookup_policy(query: str) -> str:\n",
    "    \"\"\"Consult the company policies to check whether certain options are permitted.\n",
    "    Use this before making any flight changes performing other 'write' events.\"\"\"\n",
    "    docs = retriever.query(query, k=2)\n",
    "    return \"\\n\\n\".join([doc[\"page_content\"] for doc in docs])\n",
    "@tool\n",
    "def update_reservation_to_new_flight(reservation_id: int, new_flight_id: int) -> bool:\n",
    "    \"\"\"\n",
    "    Update a reservation to a new flight.\n",
    "    \"\"\"\n",
    "    with engine.begin() as connection:\n",
    "        # Check if the reservation exists\n",
    "        check_reservation = text(\"SELECT flight_id FROM reservations WHERE reservation_id = :reservation_id\")\n",
    "        old_flight_id = connection.execute(check_reservation, {\"reservation_id\": reservation_id}).scalar()\n",
    "        if not old_flight_id:\n",
    "            return False\n",
    "\n",
    "        # Check if the new flight exists and has available seats\n",
    "        check_flight = text(\"\"\"\n",
    "            SELECT (a.capacity - f.number_of_reserved_seats) as available_seats\n",
    "            FROM flights f\n",
    "            JOIN airplanes a ON f.airplane_id = a.airplane_id\n",
    "            WHERE f.flight_id = :flight_id\n",
    "        \"\"\")\n",
    "        available_seats = connection.execute(check_flight, {\"flight_id\": new_flight_id}).scalar()\n",
    "        if available_seats is None or available_seats <= 0:\n",
    "            return False\n",
    "\n",
    "        # Update the reservation\n",
    "        update_reservation = text(\"\"\"\n",
    "            UPDATE reservations \n",
    "            SET flight_id = :new_flight_id \n",
    "            WHERE reservation_id = :reservation_id\n",
    "        \"\"\")\n",
    "        connection.execute(update_reservation, {\n",
    "            \"new_flight_id\": new_flight_id,\n",
    "            \"reservation_id\": reservation_id\n",
    "        })\n",
    "\n",
    "        # Update the seat counts\n",
    "        update_old_flight = text(\"\"\"\n",
    "            UPDATE flights \n",
    "            SET number_of_reserved_seats = number_of_reserved_seats - 1 \n",
    "            WHERE flight_id = :flight_id\n",
    "        \"\"\")\n",
    "        update_new_flight = text(\"\"\"\n",
    "            UPDATE flights \n",
    "            SET number_of_reserved_seats = number_of_reserved_seats + 1 \n",
    "            WHERE flight_id = :flight_id\n",
    "        \"\"\")\n",
    "        connection.execute(update_old_flight, {\"flight_id\": old_flight_id})\n",
    "        connection.execute(update_new_flight, {\"flight_id\": new_flight_id})\n",
    "\n",
    "    return True\n",
    "@tool\n",
    "def cancel_reservation(reservation_id: int) -> bool:\n",
    "    \"\"\"\n",
    "    Cancel a reservation (reservation).\n",
    "    \"\"\"\n",
    "    with engine.begin() as connection:\n",
    "        # Check if the reservation exists\n",
    "        check_reservation = text(\"SELECT flight_id, status FROM reservations WHERE reservation_id = :reservation_id\")\n",
    "        result = connection.execute(check_reservation, {\"reservation_id\": reservation_id}).first()\n",
    "        if not result:\n",
    "            return False\n",
    "        flight_id, status = result\n",
    "\n",
    "        if status == 'Cancelled':\n",
    "            return False  # Already cancelled\n",
    "\n",
    "        # Update the reservation status\n",
    "        update_reservation = text(\"\"\"\n",
    "            UPDATE reservations \n",
    "            SET status = 'Cancelled' \n",
    "            WHERE reservation_id = :reservation_id\n",
    "        \"\"\")\n",
    "        connection.execute(update_reservation, {\"reservation_id\": reservation_id})\n",
    "\n",
    "        # Update the flight's reserved seats count\n",
    "        update_flight = text(\"\"\"\n",
    "            UPDATE flights \n",
    "            SET number_of_reserved_seats = number_of_reserved_seats - 1 \n",
    "            WHERE flight_id = :flight_id\n",
    "        \"\"\")\n",
    "        connection.execute(update_flight, {\"flight_id\": flight_id})\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 23 key-value pairs and 291 tensors from C:/Users/waled/.cache/lm-studio/models/NousResearch/Hermes-2-Pro-Llama-3-8B-GGUF/Hermes-2-Pro-Llama-3-8B-Q6_K.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = Hermes-2-Pro-Llama-3-8B\n",
      "llama_model_loader: - kv   2:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   3:                       llama.context_length u32              = 8192\n",
      "llama_model_loader: - kv   4:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
      "llama_model_loader: - kv   6:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   7:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv   8:                       llama.rope.freq_base f32              = 500000.000000\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  10:                          general.file_type u32              = 18\n",
      "llama_model_loader: - kv  11:                           llama.vocab_size u32              = 128288\n",
      "llama_model_loader: - kv  12:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv  13:                       tokenizer.ggml.model str              = gpt2\n",
      "llama_model_loader: - kv  14:                         tokenizer.ggml.pre str              = llama-bpe\n",
      "llama_model_loader: - kv  15:                      tokenizer.ggml.tokens arr[str,128288]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
      "llama_model_loader: - kv  16:                  tokenizer.ggml.token_type arr[i32,128288]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
      "llama_model_loader: - kv  17:                      tokenizer.ggml.merges arr[str,280147]  = [\"Ġ Ġ\", \"Ġ ĠĠĠ\", \"ĠĠ ĠĠ\", \"...\n",
      "llama_model_loader: - kv  18:                tokenizer.ggml.bos_token_id u32              = 128000\n",
      "llama_model_loader: - kv  19:                tokenizer.ggml.eos_token_id u32              = 128003\n",
      "llama_model_loader: - kv  20:            tokenizer.ggml.padding_token_id u32              = 128001\n",
      "llama_model_loader: - kv  21:                    tokenizer.chat_template str              = {{bos_token}}{% for message in messag...\n",
      "llama_model_loader: - kv  22:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q6_K:  226 tensors\n",
      "llm_load_vocab: special tokens cache size = 288\n",
      "llm_load_vocab: token to piece cache size = 0.8007 MB\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = BPE\n",
      "llm_load_print_meta: n_vocab          = 128288\n",
      "llm_load_print_meta: n_merges         = 280147\n",
      "llm_load_print_meta: vocab_only       = 0\n",
      "llm_load_print_meta: n_ctx_train      = 8192\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 8\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_swa            = 0\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 4\n",
      "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
      "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 14336\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: causal attn      = 1\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 500000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_ctx_orig_yarn  = 8192\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: model type       = 8B\n",
      "llm_load_print_meta: model ftype      = Q6_K\n",
      "llm_load_print_meta: model params     = 8.03 B\n",
      "llm_load_print_meta: model size       = 6.14 GiB (6.56 BPW) \n",
      "llm_load_print_meta: general.name     = Hermes-2-Pro-Llama-3-8B\n",
      "llm_load_print_meta: BOS token        = 128000 '<|begin_of_text|>'\n",
      "llm_load_print_meta: EOS token        = 128003 '<|im_end|>'\n",
      "llm_load_print_meta: PAD token        = 128001 '<|end_of_text|>'\n",
      "llm_load_print_meta: LF token         = 128 'Ä'\n",
      "llm_load_print_meta: EOT token        = 128003 '<|im_end|>'\n",
      "llm_load_print_meta: max token length = 256\n",
      "llm_load_tensors: ggml ctx size =    0.14 MiB\n",
      "llm_load_tensors:        CPU buffer size =  6283.17 MiB\n",
      ".........................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 10016\n",
      "llama_new_context_with_model: n_batch    = 300\n",
      "llama_new_context_with_model: n_ubatch   = 300\n",
      "llama_new_context_with_model: flash_attn = 0\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:        CPU KV buffer size =  1252.00 MiB\n",
      "llama_new_context_with_model: KV self size  = 1252.00 MiB, K (f16):  626.00 MiB, V (f16):  626.00 MiB\n",
      "llama_new_context_with_model:        CPU  output buffer size =     0.49 MiB\n",
      "llama_new_context_with_model:        CPU compute buffer size =   397.78 MiB\n",
      "llama_new_context_with_model: graph nodes  = 1030\n",
      "llama_new_context_with_model: graph splits = 1\n",
      "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | AVX512_BF16 = 0 | FMA = 1 | NEON = 0 | SVE = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \n",
      "Model metadata: {'general.name': 'Hermes-2-Pro-Llama-3-8B', 'general.architecture': 'llama', 'llama.block_count': '32', 'llama.context_length': '8192', 'tokenizer.ggml.eos_token_id': '128003', 'general.file_type': '18', 'llama.attention.head_count_kv': '8', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '14336', 'llama.attention.head_count': '32', 'llama.rope.freq_base': '500000.000000', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.vocab_size': '128288', 'llama.rope.dimension_count': '128', 'tokenizer.ggml.model': 'gpt2', 'tokenizer.ggml.pre': 'llama-bpe', 'general.quantization_version': '2', 'tokenizer.ggml.bos_token_id': '128000', 'tokenizer.ggml.padding_token_id': '128001', 'tokenizer.chat_template': \"{{bos_token}}{% for message in messages %}{{'<|im_start|>' + message['role'] + '\\n' + message['content'] + '<|im_end|>' + '\\n'}}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\\n' }}{% endif %}\"}\n",
      "Available chat formats from metadata: chat_template.default\n",
      "Using gguf chat template: {{bos_token}}{% for message in messages %}{{'<|im_start|>' + message['role'] + '\n",
      "' + message['content'] + '<|im_end|>' + '\n",
      "'}}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\n",
      "' }}{% endif %}\n",
      "Using chat eos_token: <|im_end|>\n",
      "Using chat bos_token: <|begin_of_text|>\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import Runnable, RunnableConfig\n",
    "from typing import Annotated\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph.message import AnyMessage, add_messages\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add_messages]\n",
    "    user_info: str\n",
    "\n",
    "\n",
    "class Assistant:\n",
    "    def __init__(self, runnable: Runnable):\n",
    "        self.runnable = runnable\n",
    "\n",
    "    def __call__(self, state: State, config: RunnableConfig):\n",
    "        while True:\n",
    "            result = self.runnable.invoke(state)\n",
    "            # If the LLM happens to return an empty response, we will re-prompt it\n",
    "            # for an actual response.\n",
    "            if not result.tool_calls and (\n",
    "                not result.content\n",
    "                or isinstance(result.content, list)\n",
    "                and not result.content[0].get(\"text\")\n",
    "            ):\n",
    "                messages = state[\"messages\"] + [(\"user\", \"Respond with a real output.\")]\n",
    "                state = {**state, \"messages\": messages}\n",
    "                messages = state[\"messages\"] + [(\"user\", \"Respond with a real output.\")]\n",
    "                state = {**state, \"messages\": messages}\n",
    "            else:\n",
    "                break\n",
    "        return {\"messages\": result}\n",
    "\n",
    "\n",
    "import multiprocessing\n",
    "from langchain_community.chat_models import ChatLlamaCpp\n",
    "local_model = \"C:/Users/waled/.cache/lm-studio/models/lmstudio-ai/gemma-2b-it-GGUF/gemma-2b-it-q4_k_m.gguf\"\n",
    "local_model = \"C:/Users/waled/.cache/lm-studio/models/NousResearch/Hermes-2-Pro-Llama-3-8B-GGUF/Hermes-2-Pro-Llama-3-8B-Q6_K.gguf\"\n",
    "llm = ChatLlamaCpp(\n",
    "    temperature=0.5,\n",
    "    model_path=local_model,\n",
    "    n_ctx=10000,\n",
    "    n_gpu_layers=8,\n",
    "    n_batch=300,  # Should be between 1 and n_ctx, consider the amount of VRAM in your GPU.\n",
    "    max_tokens=512,\n",
    "    n_threads=multiprocessing.cpu_count() - 1,\n",
    "    repeat_penalty=1.5,\n",
    "    top_p=0.5,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "assistant_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful customer support assistant for Cham Wings Airlines. \"\n",
    "            \" Use the provided tools to search for flights, company policies, and other information to assist the user's queries. \"\n",
    "            \" When searching, be persistent. Expand your query bounds if the first search returns no results. \"\n",
    "            \" If a search comes up empty, expand your search before giving up.\"\n",
    "            \"\\n\\nCurrent user:\\n\\n{user_info}\\n\",\n",
    "       \n",
    "        ),\n",
    "        (\"placeholder\", \"{messages}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# \"Read\"-only tools (such as retrievers) don't need a user confirmation to use\n",
    "part_3_safe_tools = [\n",
    "    TavilySearchResults(max_results=1),\n",
    "    fetch_user_flight_information,\n",
    "    search_flights,\n",
    "    lookup_policy,\n",
    "]\n",
    "\n",
    "# These tools all change the user's reservations.\n",
    "# The user has the right to control what decisions are made\n",
    "part_3_sensitive_tools = [\n",
    "    update_reservation_to_new_flight,\n",
    "    cancel_reservation,\n",
    "]\n",
    "sensitive_tool_names = {t.name for t in part_3_sensitive_tools}\n",
    "# Our LLM doesn't have to know which nodes it has to route to. In its 'mind', it's just invoking functions.\n",
    "part_3_assistant_runnable = assistant_prompt | llm.bind_tools(\n",
    "    part_3_safe_tools + part_3_sensitive_tools\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import ToolMessage\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "\n",
    "def handle_tool_error(state) -> dict:\n",
    "    error = state.get(\"error\")\n",
    "    tool_calls = state[\"messages\"][-1].tool_calls\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            ToolMessage(\n",
    "                content=f\"Error: {repr(error)}\\n please fix your mistakes.\",\n",
    "                tool_call_id=tc[\"id\"],\n",
    "            )\n",
    "            for tc in tool_calls\n",
    "        ]\n",
    "    }\n",
    "\n",
    "\n",
    "def create_tool_node_with_fallback(tools: list) -> dict:\n",
    "    return ToolNode(tools).with_fallbacks(\n",
    "        [RunnableLambda(handle_tool_error)], exception_key=\"error\"\n",
    "    )\n",
    "\n",
    "\n",
    "def _print_event(event: dict, _printed: set, max_length=1500):\n",
    "    current_state = event.get(\"dialog_state\")\n",
    "    if current_state:\n",
    "        print(\"Currently in: \", current_state[-1])\n",
    "    message = event.get(\"messages\")\n",
    "    if message:\n",
    "        if isinstance(message, list):\n",
    "            message = message[-1]\n",
    "        if message.id not in _printed:\n",
    "            msg_repr = message.pretty_repr(html=True)\n",
    "            if len(msg_repr) > max_length:\n",
    "                msg_repr = msg_repr[:max_length] + \" ... (truncated)\"\n",
    "            print(msg_repr)\n",
    "            _printed.add(message.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.prebuilt import tools_condition\n",
    "\n",
    "builder = StateGraph(State)\n",
    "\n",
    "\n",
    "def user_info(state: State):\n",
    "    return {\"user_info\": fetch_user_flight_information.invoke({})}\n",
    "\n",
    "\n",
    "# NEW: The fetch_user_info node runs first, meaning our assistant can see the user's flight information without\n",
    "# having to take an action\n",
    "builder.add_node(\"fetch_user_info\", user_info)\n",
    "builder.add_edge(START, \"fetch_user_info\")\n",
    "builder.add_node(\"assistant\", Assistant(part_3_assistant_runnable))\n",
    "builder.add_node(\"safe_tools\", create_tool_node_with_fallback(part_3_safe_tools))\n",
    "builder.add_node(\n",
    "    \"sensitive_tools\", create_tool_node_with_fallback(part_3_sensitive_tools)\n",
    ")\n",
    "# Define logic\n",
    "builder.add_edge(\"fetch_user_info\", \"assistant\")\n",
    "\n",
    "\n",
    "def route_tools(state: State) -> Literal[\"safe_tools\", \"sensitive_tools\", \"__end__\"]:\n",
    "    next_node = tools_condition(state)\n",
    "    # If no tools are invoked, return to the user\n",
    "    if next_node == END:\n",
    "        return END\n",
    "    ai_message = state[\"messages\"][-1]\n",
    "    # This assumes single tool calls. To handle parallel tool calling, you'd want to\n",
    "    # use an ANY condition\n",
    "    first_tool_call = ai_message.tool_calls[0]\n",
    "    if first_tool_call[\"name\"] in sensitive_tool_names:\n",
    "        return \"sensitive_tools\"\n",
    "    return \"safe_tools\"\n",
    "\n",
    "\n",
    "builder.add_conditional_edges(\n",
    "    \"assistant\",\n",
    "    route_tools,\n",
    ")\n",
    "builder.add_edge(\"safe_tools\", \"assistant\")\n",
    "builder.add_edge(\"sensitive_tools\", \"assistant\")\n",
    "\n",
    "memory = MemorySaver()\n",
    "part_3_graph = builder.compile(\n",
    "    checkpointer=memory,\n",
    "    # NEW: The graph will always halt before executing the \"tools\" node.\n",
    "    # The user can approve or reject (or even alter the request) before\n",
    "    # the assistant continues\n",
    "    interrupt_before=[\"sensitive_tools\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/4gHYSUNDX1BST0ZJTEUAAQEAAAHIAAAAAAQwAABtbnRyUkdCIFhZWiAH4AABAAEAAAAAAABhY3NwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAQAA9tYAAQAAAADTLQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAlkZXNjAAAA8AAAACRyWFlaAAABFAAAABRnWFlaAAABKAAAABRiWFlaAAABPAAAABR3dHB0AAABUAAAABRyVFJDAAABZAAAAChnVFJDAAABZAAAAChiVFJDAAABZAAAAChjcHJ0AAABjAAAADxtbHVjAAAAAAAAAAEAAAAMZW5VUwAAAAgAAAAcAHMAUgBHAEJYWVogAAAAAAAAb6IAADj1AAADkFhZWiAAAAAAAABimQAAt4UAABjaWFlaIAAAAAAAACSgAAAPhAAAts9YWVogAAAAAAAA9tYAAQAAAADTLXBhcmEAAAAAAAQAAAACZmYAAPKnAAANWQAAE9AAAApbAAAAAAAAAABtbHVjAAAAAAAAAAEAAAAMZW5VUwAAACAAAAAcAEcAbwBvAGcAbABlACAASQBuAGMALgAgADIAMAAxADb/2wBDAAMCAgMCAgMDAwMEAwMEBQgFBQQEBQoHBwYIDAoMDAsKCwsNDhIQDQ4RDgsLEBYQERMUFRUVDA8XGBYUGBIUFRT/2wBDAQMEBAUEBQkFBQkUDQsNFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBT/wAARCAFUAasDASIAAhEBAxEB/8QAHQABAAMAAwEBAQAAAAAAAAAAAAUGBwMECAIJAf/EAFkQAAEDBAADAgUNCgsGBAcBAAEAAgMEBQYRBxIhEzEIFBYiQRUXUVJVVmGRk5SV0dMjMjZTcXWBs9LUNDc4QlRydJKhscEJGCRisrQzNUODJkRGV2NzgqL/xAAbAQEBAAMBAQEAAAAAAAAAAAAAAQIDBAUGB//EADURAQABAgIGBwcEAwEAAAAAAAABAhEDURITITFSkQQUQWFxodEVIiNTgcHSBTOisTLh8PH/2gAMAwEAAhEDEQA/AP1TREQEREBERAREQEREBERAX8JABJOgFG329CzwRCKB1ZXVD+zpqRh0ZX/Cf5rQOrnegDuJ0DFjCYbt92yOU3uZxDvFZOlHF/ysi7nD4ZOZ3wgdBupoi2lXNo81tmlZMktELy2S60Ubh3h1QwH/ADXz5VWX3YoPnLPrXxFiNihYGR2W3RsHc1tJGAP8F9+Stl9x6D5sz6ll8Hv8jYeVVl92KD5yz608qrL7sUHzln1p5K2X3HoPmzPqTyVsvuPQfNmfUnwe/wAl2HlVZfdig+cs+tPKqy+7FB85Z9aeStl9x6D5sz6k8lbL7j0HzZn1J8Hv8jYeVVl92KD5yz61yQZDaqp4ZDc6OV57msqGOP8AgVx+Stl9x6D5sz6lxzYdYKhvLLY7bI32H0kZH+SfB7/JNiYRVc4nLj7e2xqXxXkH/lc8hNHL17h0JiPoDmdB6Wu1pTNmvEN7oW1MTJIXAlktPMAJIZB98x4BI2D7BIPQgkEE4VUREaVM3j/t5Z30RFqQREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREFYsurtmV8r38rhbiy2U/ftm2RzTEf1i+IH/wDUFZ1WMVb4nf8AKqN2w81zKxmxoGOSGMA79PnxyD9Cs66Mf/KI7o/qFkXFVVUNFTTVFRKyCnhYZJJZHBrWNA2XEnuAHXa5V0L/AA09RYrjFVUb7jSyU0jZaONvM6dhaQ6MDY2XDY1v0rnRlF/8KnDIeGGX5hjtRUZEzH6Dxw07aGqgE/PzCEtc6HrG9zSO1aHMABcToEqai8IXDqfA7ZlVyqq+30NdK2ljZLZ60TPn5OcsZCYe1cAA48wbykAkHosMx/H8vyLhtxQwPHLVlQwV+JSUthpczofFKykrXMlYKGF79OlhDAwBzuYNOmh5CsmUZzkeT4nw+FLY8/x7FopnUmSxWy01EF3DmUzTC2NrW9r2JkLmuliH80AOAJKDWqvj9w/ocJtOXTZLTtxy6VYoaSvEUjmvnPP9zc0N5mOHZvBDgNFujo6Cql38KjHLdxAxLH46G8S0N9oaqs8ddZLg2WIxStiYzsPF+fznF+3HQYGtJ6SNJx3EMEvrcYx6glxXI6dtNxfbeRDd6eSedlC9sksdRLJt4cBzt53lx0/YceZa/wAYZrhiXGvh5mjcfvN+slHbrpbav1DoX1k9PJN4u+JzombdynsXjmA0DretoNvRfLHc7GuAIBG9EaK+kBVg6tHEFjI9NhvNI+SRo31ngLAHexsxv0T7EbfYVnVYuTfHOINkibs+JUdTUyHXQc5jjYN/D90/uldGDvqid1p/q8edlhZ0RFzoIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiCBv1sqY6+nvVtiE1fTMMMlNzBvjUBILmAkgB4I5mF3Te2ktDy4fFXTY5xNx6qttwo6S92uUtbV26vgDw1zXB4ZLE8ea4ODTpw2CAVYVD3jErXe6htTPA+KsaAG1lJM+CcAdw52EOI+Akj4FviqmqIpr7O1fFTx4NnCcd3DfFh+S0wfsrt2fgHw1x66UtyteBY5b7hSyCWCqprZDHJE8dzmuDdgj2QpXyIlaOWPJ79G0dw8Yjd/i6Mn/FPImo99V++Wh+yV1eHx+UlozWhFV/Imo99V++Wh+yVA4+uvXDTgzl+U2jKLu652q3yVNOKl8T4y8a1zARgkfpTV4fH5SWjNs6LPMIsFwyHDLBdarKb2Kmut9PUyiOWEN53xtc7Q7LoNkqb8iaj31X75aH7JNXh8flJaM0FUeDnwrq6iWefh1jE00ri98j7TAXOcTsknl6klcf8Au18J/wD7b4sfy2iD9lWHyJqPfVfvlofskGDyOI7XJb9M0fzfGmM3+ljGn/FNXh8flJaM3dqbhasMttFbqWnbGI4mwUFpoIxzuawBrWRRjQDWjQ2dNaOpLQNr6x2zzUJqq6vMb7tXOD6gxElkYaNMiYTolrR6dDmcXO03m0OWy4xbMfMjqKm5ZpBqSpmkdNPIPQHSvJe7vPeT3lSixqqppiaaO3tPAREWlBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAWP+F//Jj4kfmeX/RbAsf8L/8Akx8SPzPL/ogvHCz+LHEPzPR/qGK0Kr8LP4scQ/M9H+oYrQgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICx/wAL/wDkx8SPzPL/AKLYFj/hf/yY+JH5nl/0QXjhZ/FjiH5no/1DFaFV+Fn8WOIfmej/AFDFaEBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBEXy97YmOe9wYxo25zjoAeyUH0ipRy++XYCps1sohbn9YZrhUyRyTN9v2bYzytPeNnZB6hvcvn1dzD+gWP53N9muzquJ22j6wtl3RUj1dzD+gWP53N9mnq7mH9Asfzub7NOq15xzgsu6KkeruYf0Cx/O5vs09Xcw/oFj+dzfZp1WvOOcFl3X5b/7UDgzU41xSo+IlMx8lrySKOnqpD1EVXDGGBvwB0TGED0lki/RH1dzD+gWP53N9mqBx04b3nj1w0umH3mjs1NDVcskFZFUSukpZmHbJGgx+jqCOm2ucNjadVrzjnBZ5d/2W3Avtqq78VLpTebDz2uz9o3+cQO3mbv2ARGCPbSD0L9GFknDfHr5wtwOx4nZrZZGW200rKaImqlDpCPvpHai1zOcXOJ9JcVZPV3MP6BY/nc32adVrzjnBZd0VI9Xcw/oFj+dzfZp6u5h/QLH87m+zTqtecc4LLuipHq7mH9Asfzub7NPV3MP6BY/nc32adVrzjnBZd0VI9Xcw/oFj+dzfZrmpsvulumiN+oKOCike2PxuhqHyCJzjpvaNcxpDdkDmBOt9QGguEnouJ2Wn6wWXFERciCIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgKGzJxbiF9IOiKCcg/+25TKhs0/A6+/wBgn/VuW3C/cp8YWN6HsQDbJbwAABTx6A/qhcDcssb8idYG3m3uvrYu3daxVM8aEfTzzFvm5eo6611XYsf/AJLb/wCzx/8ASF5HxO+Xzg5gnGLMhdpsovwy2azU4rKGlYX1Dp4IGzvcxsZPR7fuZe1nmADk2Su7Em1Uo9ir5jkZNG18bmvY4ba5p2CPZBXm223DizVU+RWy9DImWCqsNY595vVBaqaooqprQWCJtNLI17HtLwQ9m2lrfOOyozBr9lWCeD1wftdpyN9Xdsx9TLdQ1lzpIHRWaB1GZX9myNjO15WRENEhcSSNk6O8NLuHpu5Xm32YUxr66moRVTspYPGZmx9tM/7yNmyOZ7tHTR1K7i838bsXyuz4rhFDW5q++3WfObX4ldKy2QRupdlwHNHFyNk07bh0b6AfZV54RZFkjM+z3C8jvflI6w+IVVLdJKWOmmfFUxyHs5GxAMJa6F2iANhw2mltsNXRZx4RmXXbA+CGYZBYqvxG70FEZqao7NknZu5mjfK8Fp7z3gqF4rZnmNp4lWuw4pJDLUVmL3mtp6CoYzs566E04puZ5HMADI4aDgDzde4EWZsNhReVIuPGSY9wxqdZBccjzyputtsslputlgoqyz1NSSDuEGJkrSA4xFzgxxA28jeuPKeI3GPBuH+e19XHeYqSis7au3XvIKG2Q1MNYJ2MMQjpZJI3scx5cC5gILSNnYWOnA9XrqXS8UFjpRU3GtprfTGRkQmqpWxML3uDWN24gbc4gAekkAKKwyyXuy0Ewv8AkUuRV08glL3UsVPFT+aAY4mxtB5A4OI5y53XRcdKg+EzWXG2YbY66grWQRx5Da4qilmoqepiqY5KyKPlcJWO5S3m5muZpwcAQVnM2i415RV5yyx47VUFLdbzb7ZU3CUQUcNZVMhfUyEgBkYcQXu2R0Gz1C86ZXxD4h09i4xZXQZa2lpcHvMsVFZzbad8VTDHBTzPjmkLefREjgCwtcDslzugErDZK25eGBWXeovtVPQ0eI0lxht76KmeGRvqKhvYtcY+doD4xJzNcHl2gXFoAGOlkPRarnEY8uCX1w7xSSEflA6LBsc4mcQZMNwbidXZJT1Foya8UdLNiraCJsFLS1dQIY+znA7V0rOdjiXOLTpw5Qt54j/gFfv7HJ/kujo83xaPGGVO+GjIiLx2IiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiIChs0/A6+/2Cf9W5TK61yoWXO3VVHKSI6iJ8LiPYcCD/AJrPDmKa4meyVjerFj/8lt/9nj/6Qqb6yGMVGKZfjldFUXO05Rcai518NVINtlmLXHsy0NLQ1zGlp6kEb2VO012qcbpILfdLXcn1FNG2LxihoZamKcAaD2mNp5d63yuAIPTr0J+/LOm9zL99CVf2S9arCqqmZiLwtpQ2EcK2YeKwVWVZLlcdTTil7LIa5s7I4xvo1rGMBJ3oudtxHeVWqLwZsepcJ8lZb5kdbaaaeCotPb17e2sskJcYnUkjWNcwt5iNvL+gAPTvv3lnTe5l++hKv7JPLOm9zL99CVf2Sx1FfDJozkqkXA2jmobbBdcpyXIJaC8018iqbpWRySdtADyM0ImtbGd9Q1rST13tdy5YhcMVyi/5bitvhvd9v4o6etpLpczR00UVOyUMfG5lPK7mJl0Qeh7wRrRn/LOm9zL99CVf2SeWdN7mX76Eq/sk1FfDJozkrNTa8m4j2q6Y1m+I2Wixu50klNUyW+/y1UpDhrQYaSLXs83NsEDoVG0Xg8UFPfI7zV5flt0u0VpqbNFWVdwjEkUE3JssMcTeWRvICJBp2ztxcQ3V48s6b3Mv30JV/ZLp3nibZsdtdTc7rFdbZbqVhknq6u01UUUTR3uc90YDR8JKaivtplNGVPj8GbF6m05FS3u43zJq2+CmbUXa61gNZF4uS6nMT42MEZjc4uBA2STzErtVPAKiuuE5FjN6y7Ksgpb5DFBNU3OujkmhYx3M0RARCNpJPU8hLumydDVtpM+t9fSw1NNRXqoppmNkimis1W5j2kbDmkR6IIIIIXL5Z03uZfvoSr+yU1FfDK6M5Ovll0y+gqYG43j1pvNO5hMslxvMlE5jt9AGtppeYa9Ox+RQNwxS88VLFJa83tFLj0FPXUdfTOsd4NY6V8EwmAeZKaMNbzRsBABJDndW6BVm8s6b3Mv30JV/ZJ5Z03uZfvoSr+yV1OJwymjKt1/A+xXHGM/sUlXcW0ma1U1XcHskj7SJ8kMcLhCeTTRyxNI5g7qT39wm6Dh5brdnkuWxz1TrlJaILKYnvb2PYxSySNdrl3zkyu2d60B0Heez5Z03uZfvoSr+yTyzpvcy/fQlX9kmor4ZXRnJRLR4NONWe8Wydlzvk9ktVebnbsanrGuttHU8znNfHGGB/muc5zWueWtJ6AK78R/wCv39jk/yXJ5Z03uZfvoSr+yXFWunzejfaaS3V9PT1Om1NVX0j6ZkcW/OAbI0FziBoADXXZI0tmHROFXTXVFoiYIiYm8tHREXiMRERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBY/4X/8AJj4kfmeX/RbAsf8AC/8A5MfEj8zy/wCiC8cLP4scQ/M9H+oYrQqvws/ixxD8z0f6hitCAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgLH/C/wD5MfEj8zy/6LYFj/hf/wAmPiR+Z5f9EF44WfxY4h+Z6P8AUMVoVX4WfxY4h+Z6P9QxWhAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBEXy57WN25waPZJ0g+kXF41D+Oj/vBPGofx0f94K2kcq8FeHX4YtTidVnHB2fBnuir7dHFBfn3PkEjJomPMjYexOw1xez7/qWHqO4e8PGofx0f94Lxl/tL+CMWecM6XPLVG2W9Yx5tS2Lq+ahe4c3d1PZuIf7Aa6QpaR3fA28Mi6ccr1bMHpOH3qdb7LaWCtvZu5lbG2NgjZqPxdu3PfocvP0HMevL19irzJ4AvBSHg3wOo624MjhyPJuS5VvNoPjiLfuEJ7j5rCXEHqHSPHoXpbxqH8dH/eCWkcqLi8ah/HR/wB4J41D+Oj/ALwS0jlRfxrg8AtIIPpC/qgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgLMLXZ7dm1KLzeqKnutRUSSGNtZE2VkEYe4NYxrhpvQDZA2TvZK09Z1w+/BCg/8Ac/WOXodGmaaKqqdk3j7so2Q+/W+xb3tWf5hF+ynrfYt72rP8wi/ZUDdOO2DWTMm4rX3zxW9GojpOSWknEImkAMcZn5OyD3BzdNL9nY9ldiTjLh0ecuw/1X58gZI2F9PFSzPjjkcznax8zWGNry3ryucDr0Lfr8Tjnml5zS3rfYt72rP8wi/ZT1vsW97Vn+YRfsqoweERhF6sd9rrLezWttdI+pfO221b4S1ruTtGFsW5mB5AJi5um116TwhMVsmLYlU5Pf6QXW92mC6AWmiq5YXxPa0mcM7MyRQku6OlDfYPUFOsYnHPMvOa7et9i3vas/zCL9lPW+xb3tWf5hF+yqbjvHq133jJkuAOoq6CptRp44KkUNS6Od745Hyc7+y5ImtDAGuc7T9nlJ7lKY/x2wbKMt8mbdfO0vTnSsjp5qSeFs7o99oIpJGNZKW6JIY46AJ9Ca/E455l5zT3rfYt72rP8wi/ZT1vsW97Vn+YRfsqs2rwhuH17u9FbaPIBLU1lW6gheaOoZC6pa5zTAZnRiNsu2nTC4OPQgEEb6eBcerXnHEnLsPZRV1LVWSu8ThmdQ1PZ1AbC18jnSGIRx6c5zWtc7zg0ObsOCdYxOOeZec1tdb6TC7la6qz08VtiqayKkqaamYI4pmyHkBLANczSWkOGjoEb0dLR1nuX/eWT88UX65q0Jc/Sfeimqd+1Z3CIi4GIiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICzrh9+CFB/wC5+sctFWeYEwxYrSRu6PjfKxw13OErwR8YK7+j/tV+Mfdex5Y42W3McrjzyjuVozq7XqC8wzWWitMUrbM22wzQytk8wiOeUtbIS13PJz8oa0aBV5vLrpZOOcU+DWPK6V93u1OMkp622H1DrqQwgSVbJXDUczWhrdNLS5zNOYe9ejkTRR5d4ZwX2gkybG8bseW0HDrydq3w2zKbcYZbdXF2mU1I8+dNG5rnnl28N5W6d10oa72u84lw14aV+PWDMqDihb8MoKKmqLbanT0cxEbN0Fe1w1GA8EkvDCzmJDtjS9domiMOxmqvGHcfssmu2O3WSLLKK0mlr7dRvqKKGaGOWOZk0rQRFyucCC7WwdrKLHQ5fe8p4ZXfIbRnlbldvyTtcglrIJm2qia9k8IFNED2ZjBkZ91ja7TA4vcNr2QiuiPLFDhl+j8HPGbebFcW3Wnztlc6l8UkE8cQvz5O2LNcwb2Z5+bWuU73rqr/AIFNX4hx24h22vsN4NNklwprjb7vBRPkoTG2hjjeJJh5sbg+FzeV2ieZut7W0ImjYV3NZ46ans8s0jYomXajc573ANaO2b1JPctDY9sjQ5pDmuGwQdghY3x5oIbpw5raSoscmURSvaXWOFzmvuAaC8wNc3qC8NLQR3bX52cRfDhu9aMNt2LYpLgEGFTNjoLfDd6l7ezYYx2FSByGVuog0h2jov3sklTpH+FH1Xsfryi8k+Apn/Erjfbsh4h5dlpqLbLUS22kxltujip2PYyBzapko8/l2ZY+XWthxJJGhsFNe+L+McMLlW3jHMfzXN4KsNpLZjlY+gpqqm3GOZ0lTvkkAMpI7ujQFwI1ZFntz4r1dhu2E2u4YTkclXkcbPGJ7ZSiqo7RMQzbKqcFoaAXOHMAd8hOl37HxhxDI8xyPFaG8xyX7HWh9zpZIpIxTsIB5i9zQwjqOoJ1133ILmijrFkVqym3MuFludHd6B5IbVUFQyeJxHeA5pIKkUBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERARV/NOIGNcObXHccnvlDYqKSVsMc1dO2MSSHua0Hq4+nQ30BPcCoxub3iq4m1GLRYhdIrPBQ+MPymV0TaQzO1yRRt5uaQ6LtnQ5S0AjR5kFvnnjpoXzTSNiijaXPke4Na0DvJJ7gqfdeLNltPFCz4C+C5z3650r6xr6ehkfTQQgP06WbXK3mMbmjqTvQOtjdWpOCFdnvDOXGOMl5gz6We4Cve6jpjb4o2tLSyECNwLmtId1OiQ4g921q9JSRUFJDTU7BHBCxscbB3NaBoD4ggzGnx/iDxHxXL7LmVTBhLKus7K012IVz/AB6Kka8ec6R7dNe8NPVo6NeQQCFO2/hVTWW10VFar7eLd4vTxwPmEsUz6nkaGiSXtY3h0hAHM8AFx6nau6LZRiVYc3plb2U3yAuHvzvfyFF+7p5A3Af/AFnevkKH93VyWWeErwuyjjFwpuOMYplnkhX1R3LOYS9tZEGP/wCGe8EOiY95j5ntDjytI5XBxad3WcTu5R6F3lXwlPDZoeGdz8neH+XV2WX+KYR1dbNDSOoKbTvOYCyBplf6PNcGjfeSC0ers7wjMqXD7tLiWVV1ZkrIHGgguMVGKd8voDyIAeX8hC/F6/8ACXK7BSXe6Ns9bc8btlZLRyZLb6SaS2PcybsuZtQWBvK5+gObRPM3oCdL9ueNVDbbrwlyilvV9lxa1zUL21N4hdp9Gzpt4I9ITrOJ3co9C7gs2B36Sz0L7nl91iuToIzVRwQ0RjbLyjnDd0580O3rr3LueQFw9+d7+Qov3dTeIQ09NidlipK11xpY6GBsNY87M7BG0NkPwuGj+lS6dZxO7lHoXU3yAuHvzvfyFF+7p5AXD353v5Ci/d1ckTrOJ3co9C6v2bDYLXWtramuq7xXMaWxT13Z/cQRp3I2NjGgn0nW/RvXReXPDO8Baj4zQ1WYYPTwUGdt8+opS8Rw3UAdxJ81k3dp50D3O9sPYaLRXXViTeqTe8q8LfAPwuycLsSZWQ3zF89ht0Trhe7Ld3U9bHUvHaSs54j2Twx7nMaeV3msb5zu82b1uOPPDzrinEm157b2fe2zN6AxzhvsCrp9Oe4+y9ul6ERYI89f7z+T4P5nE3hFkuOxN+/u9g5bzQAe3e6LT4wfYLSVfMH47cL+MULqfH8qst7kqYzE+3yyNZUPYRotdBIA/R2QQW6WkrPOIXg9cN+KnaOyjDbVc6l/fWiDsar5aPlk/wD9IOG/+DtgF/4enCPUJlqxvxrx1lHaJX0Yjn2TztMZGup7u74OgXeuXC+oqs2xi+0WXX+10Flp/Fn2GnqR4jWtAcGmZhGy8bHnb/mj4Vmn+7BlOD+fwy4vZJj0TOrLRkHLeaAD2jGy6fG34Q4lfz1y+PXDrzcs4aWvPLez7654PXmOYN9k0k/nPcfYYdbQaPbrRxFslXm9ZU5BbMlgnZJNjdskofFDSv08shmlaTzs32befW/vj8Ch7hxK4gYjwutV8vXDie95VLVmnrrFjNW2bxeLcmpmufrmBDGeaOoMg9gqGxjwzOGF7uTLVdrrV4PfToOtWX0b7bMwnpoueOz7+nR62qirqa5UsVVSVEVVTSjmjmheHsePZBHQhBUbhxYtFr4oWnAqikuYvNzpDVwVDKJ7qPQEhcx0481rwInHR9lvshd3GuKGJZjLfYrNkNBcJLFUPproyKYbo5Guc0iQHXKNsfonoeU6J0rQoC64Djl6tN6tlXZaN1FeozDcY44hGathBBEjm6LuhPXfpKCcilZPG2SN7ZI3DbXsOwR7IK+1l938HfGKvDcbxaz1l7xCzY/U+M0MWPXKSneDtxLXvPM5zSXu2CfSpx2G5J66bMkZmtUzGfFOwkxU0UZhdJo6lEx89p2d6HfoILoizGhufFmw4nlVXd7NjuU3unmLrFbrFUSUgq4djTZ5JyWskGz1Hm9PhX3cuL90xq0YVNe+H+R+qeQyMp6qiskLbiyzyuLR/wATK0taGAv1zjp0PTog0tFTaHi/idx4n3Hh5BdC/L7fStrai3mnlHLAQwh/acvIR90Z05t9e5T2P5TZctonVlju9BeaRrzG6e31LJ4w4d7S5hI31HT4UEoiIgIiICIiAiIgIiICIiAiIgIiICIiAiLJbPiddnz+JVgzHNrXmFjuDzQNsdpp20z7PCQ/7nJIyRz+1c17SebWuQEaB0gseb8YsawC44tQXGaqqKvJawUdtjt9JJUiR22hzi5gLWtaHgkk92yAdHXXhbxAvmY5ZbblBa7NhTqPxe03O3VL3XN8z2DmlII5GBvM4Ad4c0HzgdizYfh9nwLGrdj9hoW2+0W6LsKWma5zxGze9cziXHr7JKmUFEw7g/aMaw60WC7VNXm/qZVProbjlJZW1QqHOe4yh7m9HDtHgHvAdravaIgIiICIiAsW8LHiLccL4YizY24uzTLqpmP2SNjtObNN5r5djq0Rs5nc3cDy771oXEbiTjnCbE6zJMpukNqtNMPOkkO3SO9DGNHV7zro0dfiWIcIbJlPHXi1Q8Y8wsjsax21UUtLiFhrCTVATHUldO3uY97PNDfY17Ac8Nr4VcO7dwm4dY/iFqA8TtNIynEmtGV/fJIR7L3lzj8Liunxsr7Za+E+U1d5sMmUWqGie6ps8I2+rZ6YwPZKu6hsypr5WYrdYcarKW35A+neKGprYjJDHNrzS9o6lu+/XxHuQfWITU9TidllpKJ1upZKGB0NG8aMDDG0tjPwtGh+hS6ouKcQYaSqx7D8vvFog4k1VrbXVNropTqTXmyPiDgCW8wd079NcdaBKvSAiIgIiICIiAiIgIiIIfJ8PsWbW19vyCzUF7oXb3T3CmZOzr8DgdH4Vidd4FWIWmqlr+H99yXhfcXnnJxu5yNppHf/AJIJC5rm/wDKOUL0IiDzkbf4SvDX+C3LFuL1sj/9OtiNnuTx6A1zdw/pcv7H4aNrxSVlPxQwbK+GU2+V1ZX0Lqu3k+wyphB5uv8Ay6XoxfEsTJ4nxysbJG8FrmPGw4HvBCCsYPxVw7iXS9viuT2q/s5eZzaGrZI9g/5mA8zfyEBWpYtnngf8I84ndcKrFKWx3NhMjbpYnm3zxu9vuItaT8LgVg3CKXiRd+MMtk4S8UL1lXC+0Sdldb7l8EdfT9oD1p6WbTXzuA6baWNHfsjl5g9xIiIPksaXh5aC8AgO11AOtj/AfEqBdOAeBXLA71hsWOUtox28VDauso7ODRNfM10bhIOyLdHcUfd38vX0rQUQZ1c+DzpZsDFoy7Icft+JiOJtuoqvcFyhZ2YDKrmBMnSIDmJ357/bFd+22bOaDOsiuNXkdDdcWqacG12TxAQTUcwawadOCS9pIeTsbBf06DSuyIMmh4g8SMb4WT3zJeHzLplcNX2XqHjNaJu1g20dq1z/AP8Ao8vf0HsqbufGS12LJ8Rx652y8Ul1ySESU7W0TpIad5GzFNI3bWOHXv6dCr8iCsWPiZiuSX2+WW236hq7tY3FlyomSgS0vwvae4fD3fCrHT1MVXAyaCVk0Lxtskbg5rh8BHeoyqxGyVjLoJbVSc10gdTV0jIWskqIyCC17xpxGnH0+lUG5eDbiL+GdNglhlu+FWSmrDXQPxy4yU9RHKS4kiV3MdEvJ0djoPQAg1VFRL1heSuz+y5Bbs0raTH7dRugq8Y8UjmZcXhsnK90zvPY7mdGSQDvs9fziV2+EmWXzOeHdnvmSY7Nid7q2yGps1QXF9MWyPa0Hma09Wta7qB98guCIiAiIgIiICIiAiIgLKcMr8JsPHrOcbtFtraLMLnR0t+utRI4mnqmf+Cx0YLzojudprdk9SVqypF4uGZU/FnHqS3WaiqMJqaGoddbo4gVNPUN12DRt4Ja7Z6Bjtd+x6Qu6IiAiIgIiICzjjXx1x7gfYoKq6dtcbzXv7C1WGgb2lZcZzoBkbB11sjbu4bHeSAYDjf4Q8fD65UuHYlbDmXE66N/4DH6Z3mwNP8A69U4HUUQ7+pBPwDbhwcFfB3kxK/T55ntzGY8UK9nLPdZG/cLew//AC9GwjUbBsjm0C7Z7g4hBXOHXAfIuJWXUfErjZ2NXeac9pY8Oidz0FjadEOcO6Wo6DbjsAj06byekERAREQRF1xa2XW6UV3lt1DLfLcyVtvuFRTNkkpTI3ldyno4AjoQCNjptUPGs9rOGlnxmx8W8qsbstvVdNQ0FVRQvp4a7lO49g+ayQt5djo3meGt2db1NdG62O3X1tM25UFNXtpahlVAKmFsnZTMO2SN2Dyuae5w6hB3kX5feGz4UWaWe5ZZwpoM7oL9b6ivmNfU2ug8XmpaZwGrY6YPIdykvbIGt3oNa6Q80sTfYngRcapeNnASz11wqnVeQWkm1XKSVxdJJJGBySuJ6uL4yxxd6Xc/sIN9REQEREBERAREQEREBdG93u341aKu63Wtgt1tpIzNUVdTII44mDvc5x6AKF4kcS8b4S4nV5JlNzitdqphovk6vkee6ONo6vedHTR17/QCsCsnD3KvCyvNJlHEyhqcb4Z00gqLLgcji2avI6sqbhr4xF8fTZkDrSXDJ/DXrZaa2yV2IcC4pDHPXgGCvyfR05ke+sVMdaJ73dR3khnpnFsVtGEY9Q2Kw2+C1WihjEVPSUzeVkbR/mSdkk9SSSSSVIUtLDRU0VPTxMp6eFgjjiiaGsY0DQaAOgAHTQXKgIiICIiAiIgIiICIiDiqWvdTSiN4jkLCGvPc066FVDg5bMls/Day0eYX+myjI4mSCru1JrsqgmV5aW6a3uaWt7h1aVba4RmiqBMSIezdzkd4brqs38Gemw2j4HYvDw/q6yuxBsc3iFRXgiZ7e3k5+YFrT9/zjuHQBBp6IiAiIgIiICIiAiIgLOOLtphfcsJvlXnTsLorPeY5JYZJuzguvO0sbSvBkaCXEgt2HHYOh6Vo6/OXw2/C7zHGOINw4eXbh3j77DSSw1lMbtLVTvreSUvhqmSQywcjSA0GPzuVzXgud3AP0aReI/AH8IPir4QvEHNLlll6gqMWt9KOyttPQQwxwVM0vNEI3hvaOayOOVunvcdOBcSdFe3EBEXxPPHTQyTTSNiijaXvkeQGtaBskk9wCD7Xnrifx7vmV5bVcM+DUMF3zCPzLtkMw57dj7CdEyO0RJN0OoxvRB2Dylqgsg4m5V4Ut7rcS4UV0tgwKlkNPfOILGkOnI++p7d7Z2uhl7hvYI80v3Xhfwrxrg7iNLjmLW5lvt0PnPd99LUSH76WV/e9511J+ADQAACv8EeAli4J2urdTTT3vJrm/t7xklxPPWXCY9SXOOy1m+5gOh6dnZOmoiAiIgIiIKvdMvqhcJ6KzW1lzlpjyzzVFQaeFj9b5A4MeXOHTem6Gx13sDpeVGW+9yz/AE1L+6rp4e4vpLo465jd7gCdd+qqQD/ABTy9aaMLDnR0Im3j9phlNoeMs9/2d+J5P91sNgbiE43plHkktTAfhLZqVzvieFZfBQ8GPOvBdyG/VcN4tORWq70zI5bc6aWm5ZWP3HLz9m/emukbrlG+fexrS9UIp8L5cfy9Uv3I3yoy33uWf6al/dU8qMt97ln+mpf3VSSJ8L5cfy9S/cjfKjLfe5Z/pqX91Tyoy33uWf6al/dVzMvNvkuk1tbXUzrjBE2oloxM0zRxuJDXuZvYaS1wBI0eU+wv5cb3brRRMrK+vpaKke9kbaiombHG5z3BrGhxIBLnEAD0kgDvT4Xy451epfucXlRlvvcs/wBNS/uqeVGW+9yz/TUv7qpJE+F8uP5epfuRvlRlvvcs/wBNS/uqeVGW+9yz/TUv7qpJfPaMEgj5m9oRzBu+uvZ1+kJ8L5cfy9S/cj/KjLfe5Z/pqX91Tyoy33uWf6al/dVJInwvlx/L1L9zBafgzluRcWXZ3xBbaM0noH7x+zmulprfaG73ziIwv7WboPujj3jeujeXaPKjLfe5Z/pqX91XNS3m311wraCmrqaorqEsFVTRTNdJTl7eZnaNB23mb1G9bHULuJ8L5cc6vUv3I3yoy33uWf6al/dVK2DKZLlVuoLhQm2XIMMrYhL2scrAQC5j9DeiQCCARsdNEE/Chqsluc4troS6qaT8HYk6+MD4lJow64mIpiNkzsv2RftmV3r4iIvLYiIiAiIgIiICIiDiqnFtLMRH2xDCRH7bp3fpVJ4G3SsvPCqw1tww9mA1krJTJjkcXZto9SvAAbyt1zAB/wB6Pv1gHhweFBxM8Gy8WCbGrNYa3GLtTOjNZcqaeWWOsa53MzbJWNALDGWggkkP79dMj8EHw0eM/F7iLjWBT09hu9I0vqLpequim8bFI1xdI4lkrYw7q2Np7PW3M2D12H6LIiICIiAiIgKCu+c4/Yqw0lfeKSmqmgF0DpQXtB7iWjqN/CpC91j7fZq+qj12kFPJK3fstaSP8lUsSpWU2OW8t86SaFk80rurpZHNDnvce8kkkkldeDhU1UzXXu3bP+lYzlIeulifu7Sf3j9Seulifu7Sf3j9S50W/VYOU849F2OD10sT93aT+8fqWA+GTw5wrwiuGksdFd6CPMbS11Raapx0ZDrbqdziPvX6139HBp7tg+hUTVYOU849DY8z+ANabJwa4EQw32titmRXeumrq2lqeksIB7ONh6d3JGH69HaFekfXSxP3dpP7x+pc6JqsHKecehsdaTiriUUbnuvlMWtBJDeZx/QANn8gXma/ZPX+FXkU1BkNxnwDg7Ry6fbZJDDc8jLT3S8vWGn6fe/fO/KQWeokTVYOU849DYicfzLAcUstHaLPXW22WujjENPSUreSOJg7gAAp+z5nYr/UeL2+60tVUcvN2LJBzlvshp6kfCusoDPR2WI3WsYeSqoKaSsppgPOiljYXNcPi0R6QSD0JVjAwq5imm8TPfHobJ2NCRfET+1iY/WuZoOl9rzGIiIgIiIM9w3+BXT88XH/ALuVT6gMN/gV0/PFx/7uVT69jF/cq8VnewnjxmeW4jmtol8oarDcANCTUX+jtMVwZFXdqA1lXzhxig5CNPaG+cTtw6KsZRxT4j5nneZUeEx3yK245Utt9MbNb7ZUw1VR2LJXOqHVVQx4aTIABEB5o3zEnQ1zibwapOKb3R3DJMjtttnpTRVlqtda2KlrYSSXNka5jjsglpcwtcR02o6+eDzZbhkNXeLPfciw6or4Iqe4RY7XinjrWxN5Iy8OY4hzWAND2FrtDvXNMSil0OQ8Tc7z2ssD8hOCVNNiVtu1RQ01DTVToLhK6obIwPkDwY9xgEdSeVvK5vnc1XqeNWcXvF+HeWV99nwjDrrYI6m4X23WeOvhiuReGltSHhxhpy3qHDXVxBeNL0PQ8Prfb86uWVsnq33GvttPa5Y5JGmIRQvke1wHLzcxMrtkuIOh0HXdDqPBhss+F2jEo8qyulx2htotM1vprhGyKvp+ZxInHZffEOLS5nIS3ptJiRn/ABWmutZeOPluF85qUYJFcKWoioaQTQxuFXzwCURc0kbhER55cW9o4tLTojtZRR5Bifg94DVOyqe8E3SxmSO42yhlY+CaamjEHL2GgGb5mvA7QO0eboFsjuEOPyX2/XGSOeSO9WWGwVVC548X8Vj7XTWgDmBImeCeY9ANAemEo+ANshwWnxOryTIrta6Wto6yldX1MUktOKWRkkUTXCIfc9xtB2C4jfnb6poyKHfOKeYWy55Nw8Zdv/jiqySlpbFcDTQkstdUDP2/Z8nK/sIoathJadmJu9k9a9VcWOLWbXHKrphlBe5ae03Wqtltt1Nb7ZJb6o00hjPjMs1QyoaXua7Zja0MDhoP1s+h6zhzY6/iJbc2mpebILfQTW2CfY0IpHtcdjXeC1wB30Ej+/fSrTcALVHldxvVpyLJcciudYLhcLVaLgIaOrqOnNK5pYXNc/lHNyObza67SYkaRQzS1FFTyzwGmnfG10kBcHGNxGy3Y6HR6bWD1OPXat8MyqqKfKa+gpo8To6l9HDT0zmSQisla6nJfEXBji1zi4EP28gOAAA0O4X7iTDX1LKLDMdqaJsrmwTzZNNE+SME8rnMFC4NJGiWhztd2z3rrXLhV5XZJY8xrq644plVLSCjqmWC4Nkhnh7TtOwkdJD90YHbIIax3nFWdoyB/FjPvWym4x+UULLDHdzEMQ9T4uyNC2v8UIM+u17fQL9h3LvTeRc1+4ncQanDs+4mW7I4LfaMWutZTU2LvoInxVdPRy9nL20zh2rZJOV5HI4Bvm9HdVokvg04zLd3Suud89QHXP1Ydi3jjfUs1fadrz9nyc/L2n3Ts+fk5uvKl+8GrGshu10lmud9p7Jdq0XG541TVjWW2uqNtLnyM5C/zi1pc1r2tcRsgrG1QpNPdMlOV+EJcMIpo6nJnU1omtsFQBp0hoGkDRIBdonQJ0ToHotC4CZa/KscuHjOV12S3Kkq+yqobtao7bXW9/I0mCaFjWje9uDtaIcNF2tnv3TgzbK/Kciv9JeL5ZK6/UEdDWi11vYscYyOynaOUlszGjkDgdcpIIPeu5w64WW/hxJeaqG5XO+Xa8TRz191vE7ZaicsjEcYPI1jQ1rRoANHp71lETEi5qFrfw5xT+vU/qSppQtb+HOKf16n9SVuo7fCr+pWF9REXkoIiICIiAoW9ZpYMclEV0vVBQTEbEVRUMY8/kaTs/Es34k8Sqmsraiy2SpdTU0DnRVddA8tkdIDp0cbh1bynYc4ddjQ1olZtBSQ03MYo2sc47c4DznH2Se8n4SvpOifo9WNRGJjTaJ7O3/S7I3t9PFrDgdeUVD8onrt4d74qH5RYOi9H2HgcU+Xol4yWLwnqHB+PXBm+4t6v231TLPG7XLJJrsquMExneugdtzCfQ17lkf+z0wvHeCvD25X3JrjS27LL9NyyUtQ7UlLSxkhjD36Lnczz7I7PfVqvSJ7DwOKfL0Lxk3j128O98VD8onrt4d74qH5RYOiew8Diny9C8ZPQdv4jYtdKhlPS5Bbpah502Hxloe78jSdlWNeVpoI6mMxyxsljPe17QQf0FWbCM+q8GmbFNLNV2DoJKZ7i91K328Xp5QO+Pu0PNAPR3J0j9EmmnSwKrzlP2NkvQaLjgnjqYY5oZGywyND2SMO2uaRsEEd4K5F8qIvKvwYvH9jm/6Cq9jX4OWr+yRf9AVhyr8GLx/Y5v8AoKr2Nfg5av7JF/0Bejg/sz4/ZexSMD46W7iLTVtdaccyQ2aKnnqaa6y0LfF7g2J/I4Qcry4uJB5Wua0u0dDovjGuOtHkdzulpfiuT2e/0dtfdYLPdKOKGor4GnlJg1KWE8xa3T3NIL270Ooyik4bcSH3bLX4jj8nC2juNkr430jr1HVUlRc5COwqKaOMnxc/flz+Vm+YeaSNrucIuFF5xnjDj2Rw8OG4fam2KqtVwlkukFVVy1LnwyCeYtcTIHGItDuZzyTtzWhYXlHb4OcdrrceH1XnuZPvZhutf4nabDHbqbUkhlkbHFR9k50sriG6cZXDRY86DRtaxgXFSgzu43K1G13bHr5bmRTVNpvdO2KdsUnMI5W8jnsewljxtrjotIOlh9TwAyO4+Dvw9s9ZYKC537Fru66VGN3OaN1PXxGWoD4C8czA50c3M1x2AQN+nV+4dtxPhbb6+93vB8c4LMqpWUkT6muoon1Y5S7le+M8gOw7TedxIBPRIme0Xji7mFbw/wCF+VZJbqF1yrrXbp6qGna0OBe1hIc4Fzdsb987TgeVrtbOgala+PsVHw4xy+X/ABy+Ul5vD4aSis0VPDJV3Gd0IkL4GRyuaI9c7uZ7m8oaebXTchk2YYjxhw3KMPxnNMeut3u1oq6SKGiucM729pC5nOWscXcoLhs6WfMxviBV2jhnkLsIdTZBgkhppLLLdKZ3qjBJRmnlkgla4sa4Hlc0SFuwCDpWZm+wXj/eOxiPGa251NHeKK5Udyjs0mOz0g9UzWyNDooGxNcWuL2kOa4OLS3Z5tA6rPEbwgJajhRmNdj8VzxXLbBUUEVTb7xSRCppmz1MTWuLdyRuY9jngOBcOh7iFWq7hFnd6v8AcOJkljp6TJPKWgu9LisldG5zqSmpH0pjfONxiZ7ZXvB2WjlaObv1yZbwlzribaeKN/qrJDj94vtJbKO02Koro5HllFOZyZpYy6MOkc5zW6JDQBs9VL1DWrrxot9BxCkw6jsV+vlwphTOr6m10jZKegFQ4iIzOc9rtENLiWtdoAk60VYuIP4BZJ+bKn9U5YrxNxXNsvyixXrHcDnxnLAyhccpivkDWU0fO19TSVcLXbqGNHO0AB4JOwW+nauIP4BZJ+bKn9U5dOBM62nxhY3wvtL/AAWH+oP8lyripf4LD/UH+S5V5M70ERFAREQZ7hv8Cun54uP/AHcq558zx+lnkhmvtthmjcWPjkrI2ua4HRBBPQg+hcGG/wACun54uP8A3cqnGwxsBDWNaCSSANdSdk/GvXxr6yq2azvQ3l1jXvhtXz2L9pPLrGvfDavnsX7Sm+RvtR8Scjfaj4lo95EJ5dY174bV89i/aTy6xr3w2r57F+0pvkb7UfEnI32o+JPeEJ5dY174bV89i/aTy6xr3w2r57F+0pvkb7UfEnI32o+JPeEJ5dY174bV89i/aTy6xr3w2r57F+0pvkb7UfEnI32o+JPeEJ5dY174bV89i/aTy6xr3w2r57F+0pvkb7UfEnI32o+JPeEJ5dY174bV89i/aTy6xr3w2r57F+0pvkb7UfEnI32o+JPeEJ5dY174bV89i/aTy6xr3w2r57F+0pvkb7UfEnI32o+JPeHQtuRWq8yPjt9zo66Rg5nMpqhkhaPZIaSurW/hzin9ep/UlTIaB3ABQ1b+HOKf16n9SVuw77b5Vf1KwvqIi8lBERAUJm16kxzD71dIQDPSUkssQPcXhp5d/p0ptQOd2iW/4Xe7fAOaoqKOVkQ7tv5Ty/46W7B0dZTp7rxfwWN7zlSweK00cXMXlrQC897j6SfhJ6/pXKuKlqG1dNFMz72RocB7G/Qoi+Z3jWM1baW8ZDarTVOYJGwV1bFC8sJIDg1zgdbBG/gK/Uaqop21TZgnFBZdmVFh1JTSVENVW1VXN4vSUFDF2lRUycpcWsbsDo1rnEkgAA7IXR9dvBg0O8tMe0ToH1Vg/bVJ4l2q28WDYLxjhsmdtx+re+qswq4ZYqiOWMsI5tlrXjQc3m0PNPVc2Lje5OrmJn/vsJ+bjfZaS11FTV2670dXS1tPQVFrlpAauKSc6iPI1xDmu9BYXb6669F2IeMdkjt+QVN1pq+wS2JsT62kuMTRKGyb7IsEbnh/OQWgAk7GtAqoT8O56rG7ebRgVFiNUMjt1XPR0stPzvpoJmvMkjmabtoMmmguOu7qdJxF4Y5BkuUZVcLdTxDnprTPb3TytEdRPS1EkronAHbQQWjZGtuHsFc04nSIi8Rf6TlPhlGQmMV4l3PKeLYtLrbdbHaxYXVniN2pY4pHy+MMa2QFpcdcpI1zdPSAVqKyS21t4j4lOzLKrNFhtkp7Cbe+ouFzp3tbM6pY4Aua7QB7gT3/AAEgK4N4tYM86bmePOOidC6QHoBs/wA9b8HEtE6yrt7dnlItaKs0PE/DbnWQ0lHltjq6qd4jigguUL3yOPQNa0O2SfYCsy6qaqav8ZujYuBl0fWYbNQvJd6l1klGwn8XytlY38jWytaPgaFoizrgXb5KbEKqteCBca6Wpj37RrWxNP5D2XMPgdv0rRV+cdP0etYmjnP+/Nsne6N9pJK+yXCmiG5ZqeSNoPslpA/zVUxOoZU4xansJ6U0bHNPe1zWgOa4ehwIII9BBCvKrt0wCxXetkrJqWWKplO5ZKOqmpjIda2/snt5joAbOzoD2Fhg4tFNM0V3tv2f+wRlL+Iur611g9rc/pis+1T1rrB7W5/TFZ9qt+swM55R+S7HaXxLDHO0NkjbI0HengELg9a6we1uf0xWfap611g9rc/pis+1TWYGc8o/I2OWKkghdzRwxxu9lrACuVdX1rrB7W5/TFZ9qnrXWD2tz+mKz7VTWYGc8o/JNjtIur611g9rc/pis+1T1rrB7W5/TFZ9qrrMDOeUfkux2lAZ8Q7DLzTjZlqqWSlhjb99JLI0sYxo9JLnAAfCpX1rrB7W5/TFZ9qu/acGstlrI6qnpZH1MYIjmqqmWodHvYPKZHO5TokbHoJHcrTj4NExVTMzMd0esmyNqbhYY4Y2HqWtAOl9oi8tiIiICIiDPcN/gV0/PFx/7uVT6gMN/gV0/PFx/wC7lU+vYxf3KvFZ3i6tvu1DdhUGhrKesFPM+mmNPK2TspWnT43aPRwPe09Qu0TobPcvK/DSCryO1cK7PDer1S0uQTX3Ja6Smuc7aiej7QtgY+bm7QjVVT6cXc3mbDgeq0TNkeoaqvpqF0DamoipzPIIYRK8N7SQgkMbvvdoE6HXoVzryBjVXQZfVcEIMvyG6NpKh98r7dW1N6qaeWqcakQUEImZI10k3Yz9CTzlocNkOcDM4JeMr4h8WK0V2UwWe523IKiSW1Mv1Q2eG208zmNgdbBE2EslYGO8Ye95Ik23R01uOkPUyLy5TerFw4D2vIo8nyFmS5zdqenpKr1Un5aKmrbm2Rohi5uRnJT75XcpcAC0Hl80T2VZ7beC/E+8MuGQ11PabXh0lwpaK63OeoNwqpKiR0hYJHuMj2Np2DQ3yNlOg1pKukPQq4H19NHWxUb6mJtXKx0kdO54Ej2NIDnBveQC5uz6OYeyvHkWVNp6GqtGT55kMV/tmFWmOjttDeqiOtuF4ljnmkexjHc8z9vgbo7bojnGgNX3CaWG5+EJRMzG61FNmlrxG1xRUjbpPAK2pf20la9kTHtZJGDFEHN5S3bQSNgKaVx6NXFU1MVHTS1E7xHDEwyPee5rQNk/EqHxMvOeWytom4hbPH6d8bjO71OgquV2+g3JcqQjp6A1/wCUdyjeNeR3Gy+DjktfWMMF8nsZpjGIgwtq52CFrQxkkoB7WQDlbJJ7Ac7vOVxolgvtFlFit15tkxqLdcaaOrppjG5hfFI0OY7lcA4baQdEAj0hdmtrYLdRz1dVNHTUsEbpZZpXBrI2NG3OcT3AAEkryNcMouuGY5l0nCrIq+/4tbLBQUhu1XVyVtHS1rqlkUktM9weAIqYvke2IOjZys8zoWrmvtsrrtwPy6Q5UbxbMoqbZYbfS27Jqu7sbNLVNgmkFXIIy7tBOOaJjRGBERo7IWOkPUeLZVbszs0V1tTqiShm/wDDkqKSamLx6HNbK1ri0gghwGiOoJCll5g4k3uKzX3McaqMhv1nkstngZiFnt92qWVl0qpWSO7VrucyVREnZx8ji9jA0lzdHYncd8prxdeIt/rbhdLnc8YpqSiorRSV80VHNcYLeyomPZRuaH88tQGFp208o6HQ1dIeglC1v4c4p/Xqf1JWHeDDV3vLK6PIa3Lae9clr7K6U9NkFRcO1rJXRva99M+KOKiMYjlaIY2k/dNOJ5QTuNb+HOKf16n9SVtw5vee6r+pWF9REXlIIiICIiDFOJPDqosldU3i008lTbKh7pqmmhbzPpXnq57Wjq5jjskDZaST1afMzxnitwY2ZnY1DCOkg04EflXq5Vm98NMXyGpfU11lpn1Mh2+oiBhkefZc9hBP6Svp+ifrOrojDx4vbtjf9fVdk73nnxKn/ERf3AvuOGOEERsawHv5RpbeeCOGkk+ptR19i5VX2i/nrIYb7m1P0lVfaL0fbfRcquUeqWhiiLa/WQw33NqfpKq+0T1kMN9zan6SqvtFfbfRcquUfkWhib2NkaWvaHNPocNhcXiVP+Ii/uBbj6yGG+5tT9JVX2ieshhvubU/SVV9ontvomVXKPyLQw7xani8/somcvXm5QNKwYZhtXn1S0Ql9PZgfu9wA0HjfVkR/nOPUcw6N6950DrdHwgw+ilEgsUFQ4a14459SAR3HUjnDfwq3sY2NjWMaGtaNBoGgB7C4ukfrcTTNPR6Zic57PptLRDjoqOC3UcFJTRNgpoI2xRRMGmsY0aAHwAALmRF8pM32yCIigIiICIiAiIgIiICIiAiIgIiICIiDPsN6Ud0HpF4uH/dyldG5cMbPda+ermrMhZLM8vc2myW4wRgn2scc7WtHwNACslyxS4U1dU1diq6aAVT+1npKyJz4zJrRewtcCwnQ2NEEjfQlxPT9Rsx/H2P5Ob6161VWHizpaUbc2VroSh4WWa3VlPVRVuRvkgkbIxs+T3KZhLTsBzH1Ba8dOrXAg9xBCt6i/UbMfx9j+Tm+tPUbMfx9j+Tm+tS1HHBZKIov1GzH8fY/k5vrT1GzH8fY/k5vrS1HHBZKIov1GzH8fY/k5vrT1GzH8fY/k5vrS1HHBZ1sew+jxu75HcqeWeaqvta2uqnTuaQxzYIoGsZoDTAyFp0dnZcd9dCdUX6jZj+Psfyc31p6jZj+Psfyc31pajjgslEUX6jZj+Psfyc31p6jZj+Psfyc31pajjgslFCZBh1symus1Tc4pKj1JqhW0sPaubEJwNMkc0HTy3ZLebYBO9bAI5/UbMfx9j+Tm+tPUbMfx9j+Tm+tLUccFkoii/UbMfx9j+Tm+tPUbMfx9j+Tm+tLUccFkooas65zivwOqj+jsT9a5fUbMfx9j+Tm+tSlgxippa/1Tu1VFW3FrHRQiniMcMDHEFwaC5xLjyjbie4AADrtNVGHEzpROyY2d8WNyxoiLymIiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiIP/Z",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(part_3_graph.get_graph(xray=True).draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hi there, what time is my flight?\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import uuid\n",
    "\n",
    "tutorial_questions = [\n",
    "    \"Hi there, what time is my flight?\",\n",
    "    \"Am i allowed to update my flight to something sooner? I want to leave later today.\",\n",
    "    \"Update my flight to sometime next week then\",\n",
    "    \"The next available option is great\",\n",
    "]\n",
    "# Update with the backup file so we can restart from the original place in each section\n",
    "# shutil.copy(backup_file, db)\n",
    "thread_id = str(uuid.uuid4())\n",
    "\n",
    "config = {\n",
    "    \"configurable\": {\n",
    "        # The passenger_id is used in our flight tools to\n",
    "        # fetch the user's flight information\n",
    "        \"passenger_id\": \"1\",\n",
    "        # Checkpoints are accessed by thread_id\n",
    "        \"thread_id\": thread_id,\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "_printed = set()\n",
    "# We can reuse the tutorial questions from part 1 to see how it does.\n",
    "for question in tutorial_questions:\n",
    "    events = part_3_graph.stream(\n",
    "        {\"messages\": (\"user\", question)}, config, stream_mode=\"values\"\n",
    "    )\n",
    "    for event in events:\n",
    "        _print_event(event, _printed)\n",
    "    snapshot = part_3_graph.get_state(config)\n",
    "    while snapshot.next:\n",
    "        # We have an interrupt! The agent is trying to use a tool, and the user can approve or deny it\n",
    "        # Note: This code is all outside of your graph. Typically, you would stream the output to a UI.\n",
    "        # Then, you would have the frontend trigger a new run via an API call when the user has provided input.\n",
    "        user_input = input(\n",
    "            \"Do you approve of the above actions? Type 'y' to continue;\"\n",
    "            \" otherwise, explain your requested changed.\\n\\n\"\n",
    "        )\n",
    "        if user_input.strip() == \"y\":\n",
    "            # Just continue\n",
    "            result = part_3_graph.invoke(\n",
    "                None,\n",
    "                config,\n",
    "            )\n",
    "        else:\n",
    "            # Satisfy the tool invocation by\n",
    "            # providing instructions on the requested changes / change of mind\n",
    "            result = part_3_graph.invoke(\n",
    "                {\n",
    "                    \"messages\": [\n",
    "                        ToolMessage(\n",
    "                            tool_call_id=event[\"messages\"][-1].tool_calls[0][\"id\"],\n",
    "                            content=f\"API call denied by user. Reasoning: '{user_input}'. Continue assisting, accounting for the user's input.\",\n",
    "                        )\n",
    "                    ]\n",
    "                },\n",
    "                config,\n",
    "            )\n",
    "        snapshot = part_3_graph.get_state(config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
